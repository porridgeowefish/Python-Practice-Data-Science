### T5

编写一个函数，该函数接受一个 NumPy 数组（ndarray）作为输入，要求返回一个新的数组，新数组只包含原数组中所有偶数行（索引为0, 2, 4...）的数据。

> 考察知识点，numpy array的创建，切片操作练习。

### T6 

编写一个函数，该函数接受一个 Pandas DataFrame 和一个年龄阈值（整数）作为输入。函数应返回一个新的 DataFrame，其中只包含 'Age' 列大于该阈值的行。
这道题基于第三题，请先完成第三题！

> 两种实现手段，mask的生成和使用，还有用query的

### T7

编写一个函数，创建两个 PyTorch 张量（Tensor）：
A 的形状为 (2, 3)
B 的形状为 (3, 4)
然后，计算这两个张量的矩阵乘法（matrix multiplication），并返回结果。
> Pytorch中的矩阵乘法

### T8
编写一个函数，执行以下操作：
创建一个值为 3.0 的浮点数张量 x，并设置 requires_grad=True。
根据 x 计算 y，公式为 y = 2*x**2 + 5。
使用 PyTorch 自动计算 y 相对于 x 的梯度（也就是导数 dy/dx）。
返回这个梯度值。
> 了解pytorch中的自动微分
### T9

编写一个函数，该函数：
接受一个 NumPy 数组作为输入。
将这个 NumPy 数组转换成一个 PyTorch 张量。
将张量中的每一个元素乘以 2。
将结果张量转换回 NumPy 数组，并返回。

> 练习数据结构的转换


### T10

探究Python中的dataloader，dataset。研究如何自己创建数据集。
研究如何用dataloader快速遍历数据集。

> Dataset的构建逻辑，以及如何使用loader


### T11
手写一个MLP，拟合一个复杂函数，给出拟合效果。

### T12
现在，请你把我们目前学到的所有东西整合起来：
- 加载你的彗星数据集 CSV 文件 (near-earth-comets.csv)。
- 创建一个为该数据集服务的 CometDataset 类（就像你在第10题做的那样）。
- 创建一个 DataLoader 来批量加载数据。
- 创建一个继承自 nn.Module 的线性回归模型 LinearRegressionModel（就像我刚刚上面展示的那样），确保输入和输出维度正确。
写一个完整的训练循环，使用 MSELoss 和 Adam 优化器，对你的模型进行至少100个 epoch 的训练。在训练过程中，每10个 epoch 打印一次当前的 loss。
这将是你第一个完整的、端到端（从原始文件到训练好的模型）的项目。




### T13

在第12题中，我们用所有的数据来训练模型。但这样做有一个问题：我们无法知道模型在**从未见过**的数据上表现如何。它可能只是“背住”了训练数据，而不是真正学会了规律（这被称为“过拟合”）。

因此，标准的做法是先将数据集分成两部分：一部分用于训练（训练集），另一部分用于评估（测试集）。

你的任务是：
1.  重新加载彗星数据集 (`near-earth-comets.csv`)。
2.  将其中的特征（X）和标签（y）分离出来。
3.  使用 `scikit-learn` 的功能，将整个数据集（X 和 y）分割成**训练集**和**测试集**。通常的分割比例是80%用于训练，20%用于测试。
4.  **重要**：对特征和标签进行标准化。正确的流程是：
    *   在**训练集**数据上 `fit` 并 `transform` `StandardScaler`。
    *   使用**同一个**已经 `fit` 好的 scaler，只对**测试集**数据进行 `transform`。（思考一下为什么不能在测试集上重新`fit`？）
5.  最终，你的代码应该产生四个变量：`X_train_scaled`, `X_test_scaled`, `y_train_scaled`, `y_test_scaled`。请将它们的形状（shape）打印出来，以确认分割和处理是否正确。

### T14

你已经彻底掌握了回归问题的端到端流程。现在我们来解决一个经典的**多类别分类（multi-class classification）**问题。

你的任务是：
1.  使用 `scikit-learn` 加载著名的 `iris` (鸢尾花) 数据集。
2.  **数据预处理**：
    *   将数据集分割成**训练集**和**测试集**（80/20比例）。
    *   对4个输入特征进行**标准化**（记住，用训练集`fit`，然后分别`transform`训练集和测试集）。
3.  构建一个新的 `IrisDataset` 类和对应的 `DataLoader`（你需要为训练和测试分别创建实例）。
4.  构建一个用于分类的神经网络，继承自 `nn.Module`。
    *   输入层有4个特征。
    *   中间可以有一个或多个隐藏层（例如，一个有16个神经元的隐藏层，使用ReLU激活）。
    *   **输出层必须有3个神经元**，因为有三种鸢尾花。
5.  **关键变化**：
    *   使用 `torch.nn.CrossEntropyLoss` 作为损失函数。注意：这个损失函数要求模型的输出是未经任何激活函数处理的原始得分（logits），而目标标签 `y` 应该是**整数**（0, 1, 2），并且形状是 `(batch_size,)`，而不是 `(batch_size, 1)`。你可能需要在 `IrisDataset` 里对标签 `y` 的数据类型做一些调整（`torch.long`）。
6.  编写完整的训练和评估循环，并在测试集上计算模型的**准确率（Accuracy）**。
