### 使用Pytorch进行深度学习任务时候，请注意：

- 对数据维度的敏感性：在深度学习任务中，一个张量的维度几乎一直都是2维以上（考虑到batch_size作为一个维度）。所以在对数据操作时候，例如压缩，展平，函数应用。都要指定相应维度。
- 对数据位置的敏感性：如果使用GPU训练，那么有些数据在CPU，有些在GPU。永远记住，在哪里产生，数据就属于哪里，一定要显式指定数据的挪动。
- Matplotlib的状态机机制，使用subplot后 plt.这个指令都是操作于子图，其实可以用ax = subplot来写，这样可读性更强。
- 了解模型的本质都是类,Dataset，Module的继承的基本要求。因为本质都是类，且Python的作用域不强制，所以我们是可以在外调用任何一个内部方法。例如我们可以直接调用CNN的conv1（假设有定义）从而获得输出。
  - Dataset：__init__, __len__,__getitem__
  - Module: __init__, forward()

- Pytorch提供的灵活度很高，我们可以通过失活一部分参数，微调模型，达到迁移学习效果的目的。其中optimizer可以让我们通过字典，选择性的为不同参数指定不同学习率。
- Python基础语法，对字典，列表的熟悉，是写出高健壮性，简洁代码的关键。例如 列表推导式的结构是：[expression for item in iterable]
- 在使用python类的时候，注意如果要调用内部的成员变量，一定要**第一个传入self**。这个有严格位置要求。
- 注意append和extend方法的区别，今天记反了。浪费时间。extend是把可迭代对象的每一个迭代单元解构出来，加入当前列表。
- 注意所有的可训练参数，都是定义在modul里面的，我还把词嵌入定义在外面了，有点可笑
- 今天一个收获是，打印维度，大小是一个好习惯。因为这能够让我们发现bug。我今天写了一个bug，导致词汇表只有两个单词。是通过我输出词汇表大小才发现的问题。
- 还有一个感受就是练习的重要性吧，很多东西一会没动，就生疏了诶。